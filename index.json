[{"authors":null,"categories":null,"content":"I am a postdoctoral researcher in the Department of Computer Science at the University of Helsinki. I am supervised by Professor Kai Puolam√§ki from the Exloratory Data Analysis group. My PhD was supervised by Associate Professor Michael Mathioudakis from the Algorithmic Data Science group. My PhD thesis is titled ‚ÄúScaling and Maintaining Machine Learning Pipelines‚Äù.\n","date":1710782477,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1724284800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a postdoctoral researcher in the Department of Computer Science at the University of Helsinki. I am supervised by Professor Kai Puolam√§ki from the Exloratory Data Analysis group. My PhD was supervised by Associate Professor Michael Mathioudakis from the Algorithmic Data Science group.","tags":null,"title":"Ananth Mahadevan","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0e643989bdefe366f2b5fddf949a36b6","permalink":"http://www.ananthmahadevan.com/home-unused/posts/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/posts/","section":"home-unused","summary":"","tags":null,"title":"Recent Posts","type":"home-unused"},{"authors":null,"categories":null,"content":"üëã Welcome to the Academic Template The Wowchemy Academic Resum√© Template for Hugo empowers you to create your job-winning online resum√© and showcase your academic publications.\nCheck out the latest demo of what you‚Äôll get in less than 10 minutes, or view the showcase.\nWowchemy makes it easy to create a beautiful website for free. Edit your site in Markdown, Jupyter, or RStudio (via Blogdown), generate it with Hugo, and deploy with GitHub or Netlify. Customize anything on your site with widgets, themes, and language packs.\nüëâ Get Started üìö View the documentation üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Guide and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to unlock rewards with sponsorship You‚Äôre looking at a Wowchemy widget This homepage section is an example of adding elements to the Blank widget.\nBackgrounds can be applied to any section. Here, the background option is set give a color gradient.\nTo remove this section, delete content/home/demo.md.\nGet inspired Check out the Markdown files which power the Academic Demo, or view the showcase.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1d1825344e8f4b25c2137e0a9c8b655f","permalink":"http://www.ananthmahadevan.com/home-unused/demo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/demo/","section":"home-unused","summary":"üëã Welcome to the Academic Template The Wowchemy Academic Resum√© Template for Hugo empowers you to create your job-winning online resum√© and showcase your academic publications.\nCheck out the latest demo of what you‚Äôll get in less than 10 minutes, or view the showcase.","tags":null,"title":"Academic Template","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4a7e3501655fed0a4b0ce814e15ff2c9","permalink":"http://www.ananthmahadevan.com/home-unused/skills/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/skills/","section":"home-unused","summary":"","tags":null,"title":"Skills","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d6682c06ff2f3dd0fc28f7e2c0702d07","permalink":"http://www.ananthmahadevan.com/home-unused/experience/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/experience/","section":"home-unused","summary":"","tags":null,"title":"Experience","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9e909a8894fd21a2eff4b3e43238d81e","permalink":"http://www.ananthmahadevan.com/home-unused/accomplishments/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/accomplishments/","section":"home-unused","summary":"","tags":null,"title":"Accomplish\u0026shy;ments","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"89201c04ad04664a30c3fb9ba7b170aa","permalink":"http://www.ananthmahadevan.com/home-unused/projects/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/projects/","section":"home-unused","summary":"","tags":null,"title":"Projects","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d927b251d3da15a737d1f66fb88d4504","permalink":"http://www.ananthmahadevan.com/home-unused/talks/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/talks/","section":"home-unused","summary":"","tags":null,"title":"Recent \u0026 Upcoming Talks","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"28f54f6e819207239a6024bbaa9d78de","permalink":"http://www.ananthmahadevan.com/home-unused/featured/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/featured/","section":"home-unused","summary":"","tags":null,"title":"Featured Publications","type":"home-unused"},{"authors":null,"categories":null,"content":" Quickly discover relevant content by filtering publications. ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"19cfbeefa99b41865496b68f2fb35bad","permalink":"http://www.ananthmahadevan.com/home-unused/publications/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/publications/","section":"home-unused","summary":" Quickly discover relevant content by filtering publications. ","tags":null,"title":"Recent Publications","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"657179738bed56748434d6ae76e8a647","permalink":"http://www.ananthmahadevan.com/home-unused/tags/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/tags/","section":"home-unused","summary":"","tags":null,"title":"Popular Topics","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6011477b6d615d7a4005aee5356c1e97","permalink":"http://www.ananthmahadevan.com/home-unused/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/contact/","section":"home-unused","summary":"","tags":null,"title":"Contact","type":"home-unused"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy‚Äôs Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"http://www.ananthmahadevan.com/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Ananth Mahadevan","Michael Mathioudakis"],"categories":[],"content":"","date":1710782477,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663003235,"objectID":"5a95cece4a06448c57da35971b035f12","permalink":"http://www.ananthmahadevan.com/publication/cost-aware-retraining/","publishdate":"2024-03-18T17:21:17.310139Z","relpermalink":"/publication/cost-aware-retraining/","section":"publication","summary":"Retraining a machine learning (ML) model is essential for maintaining its performance as the data change over time. However, retraining is also costly, as it typically requires re-processing the entire dataset. As a result, a trade-off arises: on the one hand, retraining an ML model too frequently incurs unnecessary computing costs; on the other hand, not retraining frequently enough leads to stale ML models and incurs a cost in loss of accuracy. To resolve this trade-off, we envision ML systems that make automated and cost-optimal decisions about when to retrain an ML model.\n\nIn this work, we study the decision problem of whether to retrain or keep an existing ML model based on the data, the model, and the predictive queries answered by the model. Crucially, we consider the costs associated with each decision and aim to optimize the trade-off. Our main contribution is a Cost-Aware Retraining Algorithm, CARA, which optimizes the trade-off over streams of data and queries. To explore the performance of CARA, we first analyze synthetic datasets and demonstrate that CARA can adapt to different data drifts and retraining costs while performing similarly to an optimal retrospective algorithm. Subsequently, we experiment with real-world datasets and demonstrate that CARA has better accuracy than drift detection baselines while making fewer retraining decisions, thus incurring lower total costs.","tags":[],"title":"Cost-aware Retraining for Machine Learning","type":"publication"},{"authors":["Ananth Mahadevan"],"categories":["Scaling up"],"content":"Improved FMMD-S An improved implementation of the FMMD-S algorithm from the paper:\nWang, Y., Mathioudakis, M., Li, J., \u0026amp; Fabbri, F. (2023). Max-Min Diversification with Fairness Constraints: Exact and Approximation Algorithms. In Proceedings of the 2023 SIAM International Conference on Data Mining (SDM) (pp. 91‚Äì99). Society for Industrial and Applied Mathematics. https://doi.org/10.1137/1.9781611977653.ch11\nTable of Contents Improved FMMD-S Table of Contents Algorithm Overview Setup Python Gurobi Cython Balanced Sampling Old FMMD-S implementation Bottlenecks Speedup over original Implementation When to parallelize? Full Experiment Results Limitations and Future Updates Algorithm Overview The FMMD-S algorithm described in the paper has the following four steps:\nObtain a greedy solution with k items using the Gonzales algorithm without regard for group constraints For each group run the Gonzales algorithm to obtain a coreset and a diversity threshold Creates a coreset graph where edges signify the distance between items are lower than the diversity threshold Create the MIS problem using the coreset graph and solve using ILP solver If solution is infeasible decrease diversity threshold and go to step 2, else return solution The FMMD-S algorithm is available in fmmd.algorithms is the fmmd function\nfmmd( features: np.ndarray, ids: np.ndarray, groups: np.ndarray, k: int, constraints: Dict[int,Tuple[int, int]], eps: float, time_limit:int = 300, verbose:bool = False, parallel_dist_update: bool = False, parallel_edge_creation: bool = False ) -\u0026gt; Tuple[set, float]: \u0026#34;\u0026#34;\u0026#34;The implementation of the Fair Max-Min Diversification algorithm. First obtains a greedy solution ignoring fairness constrains. Then obtains a coreset by getting greedy solutions in each group. Solves the MIS problem on the coreset. Args: features (np.ndarray): The feature vectors of the items ids (np.ndarray): The ids of the items groups (np.ndarray): The group (int) of the items k (int): The minimum number of total samples required constraints (List[Tuple[int,int]]): The list of lower and upper limits on number of samples for each group eps (float): The fraction to relax the diversity to get a solution. time_limit (int): The maximum number of seconds for Gurobi solver verbose (bool, optional): Print many debug statements. Defaults to False. parallel_dist_update (bool, optional): Whether to update distances in parallel. Defaults to False. parallel_edge_creation (bool, optional): Whether to create coreset graph edges in parallel. Defaults to False. Returns: Tuple[set,float]: Returns the solution as set of item ids and the solution diversity \u0026#34;\u0026#34;\u0026#34; Setup Python conda env create -n fmmd -f env.yaml Gurobi The FMMD-S algorithm uses Gurobi to solve the MIS problem as explained in the paper.\nThe gurobi optimizer can be used without a license for small datasets, but for larger datasets it is recommended to have an academic licence.\nCython This library uses Cython to compile and parallelize several utility functions.\nRun the following command to build the module:\npython setup.py build_ext --inplace After building, the module is used like this:\nfrom fmmd.parallel_utils pdist import numpy as np X = np.random.random(1000,512) d = pdist(X) The .pyx is found in ctython/parallel_utils.pyx and can be modified to add additional metrics and functionalities.\nBalanced Sampling This library was developed specifically to perform balanced sampling.\nBalanced sampling is when there is a need to uniformly sample from groups instead of the typical proportional sampling. Specifically, we wanted to perform balanced sampling when the distribution of groups was very skewed. This means that there are some groups with very few items and some groups with a lot of items. Furthermore, if min_group_size is the size of the smallest group and k\u0026gt;min_group_size then we might be forced to take all items from smaller groups.\nFor example, assume we have the following group sizes:\ngroup count 1 2 2 5 3 10 4 200 Now, if we want to sample at least ten items uniformly k\u0026gt;=10 then, we would need to select all items from group 1 and 3 items from the remaining groups. This would result in k=11 items where we take a maximum of 3 from each group. This is what the find_num_samples_per_group method in the datasets/naive_balanced_sampling.py does. It returns num_samples_per_group,total_number_of_samples for a given group distribution and minimum number of samples.\nOld FMMD-S implementation Bottlenecks This sort of balanced sampling constraints causes several bottlenecks in the original FMMD-S implementation:\nWhen entire groups need to be selected, the diversity threshold is relaxed several times until the constraints is not under_capped The coreset graph typically is much larger as several groups are added directly. This results in a long time to compute the edges which satisfy the diversity constraints When the ILP is infeasible steps 1 and 2 need to performed again We fix these issues in the new ‚Ä¶","date":1707696e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1724284800,"objectID":"68a5017f15df2b6116951916e2cf5c34","permalink":"http://www.ananthmahadevan.com/post/improved-fmmds/","publishdate":"2024-02-12T00:00:00Z","relpermalink":"/post/improved-fmmds/","section":"post","summary":"A faster implementation of the FMMD (Fair Max-Min Diversification) algorithm","tags":["Academic"],"title":"Scaling Up Constraint-Based Diverse Sampling","type":"post"},{"authors":["Ananth Mahadevan","Michael Mathioudakis","Eetu M√§kel√§","Mikko Tolonen"],"categories":[],"content":"","date":1705190400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1708708835,"objectID":"0409f8decdc799483ed9a4272138b9f1","permalink":"http://www.ananthmahadevan.com/publication/textreuse/","publishdate":"2024-01-14T17:21:17.82415Z","relpermalink":"/publication/textreuse/","section":"publication","summary":"Text reuse is a methodological element of fundamental importance in humanities research: pieces of text that re-appear across different documents, verbatim or paraphrased, provide invaluable information about the historical spread and evolution of ideas. Large modern digitized corpora enable the joint analysis of text collections that span entire centuries and the detection of large-scale patterns, impossible to detect with traditional small-scale analysis. For this opportunity to materialize, it is necessary to develop efficient data science systems that perform the corresponding analysis tasks. In this paper, we share insights from ReceptionReader, a system for analyzing text reuse in large historical corpora. The system is built upon billions of instances of text reuses from large digitized corpora of 18th-century texts. Its main functionality is to perform downstream text reuse analysis tasks, such as finding reuses that stem from a given article or identifying the most reused quotes from a set of documents, with each task expressed as a database query. For the purposes of the paper, we discuss the related design choices including various database normalization levels and query execution frameworks, such as distributed data processing (Apache Spark), indexed row store engine (MariaDB Aria), and compressed column store engine (MariaDB Columnstore). Moreover, we present an extensive evaluation with various metrics of interest (latency, storage size, and computing costs) for varying workloads, and we offer insights from the trade-offs we observed and the choices that emerged as optimal in our setting. In summary, our results show that (1) for the workloads that are most relevant to text-reuse analysis, the MariaDB Aria framework emerges as the overall optimal choice, (2) big data processing (Apache Spark) is irreplaceable for all processing stages of the system's pipeline.","tags":[],"title":"Optimizing a Data Science System for Text Reuse Analysis","type":"publication"},{"authors":["Yann Ryan","Ananth Mahadevan","Mikko Tolonen"],"categories":[],"content":"","date":1703203200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671729635,"objectID":"5e82b4e7a9ecbbc902fcdfa53308b470","permalink":"http://www.ananthmahadevan.com/publication/mandeville/","publishdate":"2023-12-22T17:21:17.82415Z","relpermalink":"/publication/mandeville/","section":"publication","summary":"Text similarity analysis entails studying identical and closely similar text passages across large corpora, with a particular focus on intentional and unintentional borrowing patterns. At a larger scale, detecting repeated passages takes on added importance, as the same text can convey different meanings in different contexts. This approach offers numerous benefits, enhancing intellectual and literary scholarship by simplifying the identification of textual overlaps. Consequently, scholars can focus on the theoretical aspects of reception with an expanded corpus of evidence at their disposal. This article adds to the expanding field of historical text reuse, applying it to intellectual history and showcasing its utility in examining reception, influence, popularity, authorship attribution, and the development of tools for critical editions. Focused on the works and various editions of Bernard Mandeville (1670‚Äì1733), the research applies comparative text similarity analysis to explore his borrowing habits and the reception of his works. Systematically examining text reuses across several editions of Mandeville‚Äôs works, it provides insights into the evolution of his output and influences over time. The article adopts a forward-looking perspective in historical research, advocating for the integration of archival and statistical evidence. This is illustrated through a detailed examination of the attribution of Publick Stews to Mandeville. Analysing cumulative negative evidence of borrowing patterns suggests that Mandeville might not have been the author of the piece. However, the article aims not to conclude the debate but rather to open it up, underscoring the importance of taking such evidence into consideration. Additionally, it encourages scholars to incorporate text reuse evidence when exploring other cases in early modern scholarship. This highlights the adaptability and scalability of text similarity analysis as a valuable tool for advancing literary studies and intellectual history.","tags":[],"title":"A Comparative text similarity analysis of the works of Bernard Mandeville","type":"publication"},{"authors":["David Rosson","Eetu M√§kel√§","Ville Vaara","Ananth Mahadevan","Yann Ryan","Mikko Tolonen"],"categories":[],"content":"","date":1681689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663003235,"objectID":"7516b1a17b1597817a8faf994f7b1c8b","permalink":"http://www.ananthmahadevan.com/publication/reception-reader/","publishdate":"2023-04-17T17:21:17.82415Z","relpermalink":"/publication/reception-reader/","section":"publication","summary":"The Reception Reader is a web tool for studying text reuse in the Early English Books Online (EEBO-TCP) and Eighteenth Century Collections Online (ECCO) data. Users can: 1) explore a visual overview of the reception of a work, or its incoming connections, across time based on shared text segments, 2) interactively survey the details of connected documents, and 3) examine the context of reused text for ‚Äúclose reading‚Äù. We show examples of how the tool streamlines research and exploration tasks, and discuss the utility and limitations of the user interface along with its current data sources.","tags":[],"title":"Reception Reader: Exploring Text Reuse in Early Modern British Publications","type":"publication"},{"authors":["Ananth Mahadevan","Arpit Merchant","Yanhao Wang","Michael Mathioudakis"],"categories":[],"content":"","date":1662163200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663003235,"objectID":"045f91598dba3ab8ee16a647bf94f719","permalink":"http://www.ananthmahadevan.com/publication/robustness-sketching/","publishdate":"2022-09-12T17:21:17.82415Z","relpermalink":"/publication/robustness-sketching/","section":"publication","summary":"Linear classifiers are well-known to be vulnerable to adversarial attacks: they may predict incorrect labels for input data that are adversarially modified with small perturbations. However, this phe- nomenon has not been properly understood in the context of sketch- based linear classifiers, typically used in memory-constrained para- digms, which rely on random projections of the features for model compression. In this paper, we propose novel Fast-Gradient-Sign Method (FGSM) attacks for sketched classifiers in full, partial, and black-box information settings with regards to their internal param- eters. We perform extensive experiments on the MNIST dataset to characterize their robustness as a function of perturbation budget. Our results suggest that, in the full-information setting, these clas- sifiers are less accurate on unaltered input than their uncompressed counterparts but just as susceptible to adversarial attacks. But in more realistic partial and black-box information settings, sketching improves robustness while having lower memory footprint.","tags":[],"title":"Robustness of Sketched Linear Classifiers to Adversarial Attacks","type":"publication"},{"authors":["Arpit Merchant","Ananth Mahadevan","Michael Mathioudakis"],"categories":[],"content":"","date":1656547200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663003235,"objectID":"ef460a14dda71dcd025691b72ba6aa1d","permalink":"http://www.ananthmahadevan.com/publication/jane/","publishdate":"2022-09-12T17:21:17.561399Z","relpermalink":"/publication/jane/","section":"publication","summary":"The task of node classification concerns a network where nodes are associated with labels, but labels are known only for some of the nodes. The task consists of inferring the unknown labels given the known node labels, the structure of the network, and other known node attributes. Common node classification approaches are based on the assumption that adjacent nodes have similar attributes and, therefore, that a node‚Äôs label can be predicted from the labels of its neighbors. While such an assumption is often valid (e.g., for political affiliation in social networks), it may not hold in some cases. In fact, nodes that share the same label may be adjacent but differ in their attributes, or may not be adjacent but have similar attributes. In this work, we present JANE (Jointly using Attributes and Node Embeddings), a novel and principled approach to node classification that flexibly adapts to a range of settings wherein unknown labels may be predicted from known labels of adjacent nodes in the network, other node attributes, or both. Our experiments on synthetic data highlight the limitations of benchmark algorithms and the versatility of JANE. Further, our experiments on seven real datasets of sizes ranging from 2.5K to 1.5M nodes and edge homophily ranging from 0.86 to 0.29 show that JANE scales well to large networks while also demonstrating an up to 20% improvement in accuracy compared to strong baseline algorithms.","tags":[],"title":"Scalably Using Node Attributes and Graph Structure for Node Classification","type":"publication"},{"authors":["Ananth Mahadevan","Michael Mathioudakis"],"categories":[],"content":"","date":1654905600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663003235,"objectID":"61a48f5a3e68474aeda389d45f81172a","permalink":"http://www.ananthmahadevan.com/publication/unlearning-pipelines/","publishdate":"2022-09-12T17:21:17.310139Z","relpermalink":"/publication/unlearning-pipelines/","section":"publication","summary":"Machine unlearning is the task of updating machine learning (ML) models after a subset of the training data they were trained on is deleted. Methods for the task are desired to combine effectiveness and efficiency (i.e., they should effectively ‚Äúunlearn‚Äù deleted data, but in a way that does not require excessive computational effort (e.g., a full retraining) for a small amount of deletions). Such a combination is typically achieved by tolerating some amount of approximation in the unlearning. In addition, laws and regulations in the spirit of ‚Äúthe right to be forgotten‚Äù have given rise to requirements for certifiability (i.e., the ability to demonstrate that the deleted data has indeed been unlearned by the ML model). In this paper, we present an experimental study of the three state-of-the-art approximate unlearning methods for logistic regression and demonstrate the trade-offs between efficiency, effectiveness and certifiability offered by each method. In implementing this study, we extend some of the existing works and describe a common unlearning pipeline to compare and evaluate the unlearning methods on six real-world datasets and a variety of settings. We provide insights into the effect of the quantity and distribution of the deleted data on ML models and the performance of each unlearning method in different settings. We also propose a practical online strategy to determine when the accumulated error from approximate unlearning is large enough to warrant a full retraining of the ML model.","tags":[],"title":"Certifiable Unlearning Pipelines for Logistic Regression: An Experimental Study","type":"publication"},{"authors":null,"categories":null,"content":"This project will use HPC to detect discourses from large historical corpora of the eighteenth century (e.g., books, pamphlets, newspapers), and study the interconnections and evolution of the detected discourses. The approach is to analyze historical corpora in a nuanced, thorough fashion: nuanced, because we analyze the available corpora at various levels of conceptual granularity, starting from the raw documents as first elements, and then progressively discovering intermediate linguistic elements (keywords, topics, genres) and higher-level notions (concepts such as ‚Äúthe economy‚Äù or ‚Äúthe state‚Äù and discourses about them); and thorough, in the sense that the analysis is performed jointly over the entire corpora (billions of words, comprising a large fraction of all existing literature from the period). This approach contrasts traditional historical scholarship, which often uses a single element as a starting point (e.g., a passage attributed to a single well-known historical figure) and then aims to generalize from it, typically using a limited number of documents as corroborating sources. In addition, our approach also contrasts modern historical scholarship, which uses ‚Äúbig data‚Äù but performs the analysis at a very aggregate level. Compared to previous scholarship, our approach has the potential to discover unknown and richer insights from historical corpora that traditional approaches have missed.\nWe expect that such discoveries will occur not through a one-shot computation, but as the outcome of historian-guided exploration in iterative computational workflows. The use of HPC is instrumental in building such workflows for the study of historical corpora. Specifically, HPC resources will be crucial for: the storage, processing, and management of large data volumes; building and deploying large and complex NLP models that are robust to noise and biases in the data; and, finally, providing the guiding historian with explanations for the results and efficiently adapting the existing workflow to the instruction of the historian. In developing and implementing its reusable workflows, the project will use the analysis of economic discourse in the eighteenth century as a case study.\n","date":1651017600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651017600,"objectID":"38d8be6db7b15c2b5dd0f1c4fad00389","permalink":"http://www.ananthmahadevan.com/project/hpc-hd/","publishdate":"2022-04-27T00:00:00Z","relpermalink":"/project/hpc-hd/","section":"project","summary":"Using HPC to detect discourses from large historical corpora of the 18th century","tags":["HPC","Machine Learning","Humanities"],"title":"HPC-HD: High Performance Computing for the Detection and Analysis of Historical Discourses","type":"project"},{"authors":["Bruno Ordozgiti","Ananth Mahadevan","Antonis Matakos","Aristides Gionis"],"categories":null,"content":"","date":1641254400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641254400,"objectID":"4b311f80728057b19958bd0ab0fee94f","permalink":"http://www.ananthmahadevan.com/publication/minsumsim/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/minsumsim/","section":"publication","summary":"When searching for information in a data collection, we are often interested not only in finding relevant items, but also in assembling a diverse set, so as to explore different concepts that are present in the data. This problem has been researched extensively. However, finding a set of items with minimal pairwise similarities can be computationally challenging, and most existing works striving for quality guarantees assume that item relatedness is measured by a distance function. Given the widespread use of similarity functions in many domains, we believe this to be an important gap in the literature. In this paper we study the problem of finding a diverse set of items, when item relatedness is measured by a similarity function. We formulate the diversification task using a flexible, broadly applicable minimization objective, consisting of the sum of pairwise similarities of the selected items and a relevance penalty term. To find good solutions we adopt a randomized rounding strategy, which is challenging to analyze because of the cardinality constraint present in our formulation. Even though this obstacle can be overcome using dependent rounding, we show that it is possible to obtain provably good solutions using an independent approach, which is faster, simpler to implement and completely parallelizable. Our analysis relies on a novel bound for the ratio of Poisson-Binomial densities, which is of independent interest and has potential implications for other combinatorial-optimization problems. We leverage this result to design an efficient randomized algorithm that provides a lower-order additive approximation guarantee. We validate our method using several benchmark datasets, and show that it consistently outperforms the greedy approaches that are commonly used in the literature.","tags":[],"title":"Provable randomized rounding for minimum-similarity diversification","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let‚Äôs make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"http://www.ananthmahadevan.com/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"}]